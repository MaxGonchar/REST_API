# Rate Limiting - API Throttling and Protection

## Introduction

**Rate limiting** controls how many requests a client can make to an API within a specific time window. It prevents abuse, ensures fair resource distribution, and protects servers from overload.

**Key principle:** Limit the number of requests per time period (e.g., 100 requests per minute).

---

## Why Rate Limiting?

### Without Rate Limiting

```javascript
// Malicious script hammering your API
for (let i = 0; i < 1000000; i++) {
  fetch('/api/expensive-operation');
}

// Result:
// ❌ Server crashes
// ❌ Database overload
// ❌ Legitimate users can't access API
// ❌ High infrastructure costs
```

### With Rate Limiting

```javascript
// After 100 requests in 1 minute:
Response: 429 Too Many Requests
Headers:
  X-RateLimit-Limit: 100
  X-RateLimit-Remaining: 0
  X-RateLimit-Reset: 1642684800
  Retry-After: 45

// Result:
// ✅ Server protected
// ✅ Fair usage for all users
// ✅ Predictable costs
```

### Benefits

1. **Prevent Abuse**
   - Stop DoS attacks
   - Prevent API scraping
   - Block malicious bots

2. **Ensure Fair Usage**
   - Equal access for all users
   - Prevent one user from consuming all resources
   - Enforce usage tiers

3. **Control Costs**
   - Limit infrastructure spending
   - Predictable resource usage
   - Prevent runaway processes

4. **Maintain Performance**
   - Keep API responsive
   - Prevent database overload
   - Protect downstream services

5. **Monetization**
   - Free tier: 100 requests/hour
   - Basic tier: 1,000 requests/hour
   - Premium tier: 10,000 requests/hour

---

## Rate Limit Headers

Standard headers to communicate limits to clients.

```http
HTTP/1.1 200 OK
X-RateLimit-Limit: 100
X-RateLimit-Remaining: 95
X-RateLimit-Reset: 1642684800
X-RateLimit-Used: 5
```

### Standard Headers

| Header | Description | Example |
|--------|-------------|---------|
| `X-RateLimit-Limit` | Maximum requests in window | `100` |
| `X-RateLimit-Remaining` | Requests left in window | `95` |
| `X-RateLimit-Reset` | When limit resets (Unix timestamp) | `1642684800` |
| `X-RateLimit-Used` | Requests consumed | `5` |
| `Retry-After` | Seconds until retry (on 429) | `45` |

### 429 Response

```http
HTTP/1.1 429 Too Many Requests
Content-Type: application/json
X-RateLimit-Limit: 100
X-RateLimit-Remaining: 0
X-RateLimit-Reset: 1642684800
Retry-After: 45

{
  "error": {
    "code": "RATE_LIMIT_EXCEEDED",
    "message": "Rate limit exceeded. Try again in 45 seconds.",
    "limit": 100,
    "remaining": 0,
    "resetAt": "2022-01-20T12:00:00Z",
    "retryAfter": 45
  }
}
```

---

## Rate Limiting Algorithms

### 1. Fixed Window

Simplest algorithm. Count requests in fixed time windows.

```javascript
// Example: 100 requests per minute
// Window 1: 12:00:00 - 12:00:59
// Window 2: 12:01:00 - 12:01:59

Time: 12:00:00 - 12:00:59
Requests: 1, 2, 3, ..., 100
Request 101: ❌ Rate limited

Time: 12:01:00
Counter resets to 0
Request 1: ✅ Allowed
```

**Implementation:**

```javascript
class FixedWindowRateLimiter {
  constructor(limit, windowMs) {
    this.limit = limit;
    this.windowMs = windowMs;
    this.requests = new Map(); // userId -> { count, windowStart }
  }
  
  isAllowed(userId) {
    const now = Date.now();
    const userRequests = this.requests.get(userId);
    
    // No previous requests or window expired
    if (!userRequests || now >= userRequests.windowStart + this.windowMs) {
      this.requests.set(userId, {
        count: 1,
        windowStart: now
      });
      return { allowed: true, remaining: this.limit - 1 };
    }
    
    // Within current window
    if (userRequests.count < this.limit) {
      userRequests.count++;
      return { 
        allowed: true, 
        remaining: this.limit - userRequests.count 
      };
    }
    
    // Rate limited
    const resetTime = userRequests.windowStart + this.windowMs;
    return { 
      allowed: false, 
      remaining: 0,
      resetAt: new Date(resetTime),
      retryAfter: Math.ceil((resetTime - now) / 1000)
    };
  }
}

// Usage
const limiter = new FixedWindowRateLimiter(100, 60000); // 100 per minute

const result = limiter.isAllowed('user123');
if (result.allowed) {
  console.log(`Request allowed. ${result.remaining} remaining.`);
} else {
  console.log(`Rate limited. Retry in ${result.retryAfter} seconds.`);
}
```

**Problem: Burst at boundaries**

```javascript
// 12:00:45 - 12:00:59: 100 requests ✅
// 12:01:00 - 12:01:14: 100 requests ✅
// = 200 requests in 30 seconds! (burst)
```

### 2. Sliding Window Log

Tracks timestamp of each request. More accurate but memory-intensive.

```javascript
class SlidingWindowLogRateLimiter {
  constructor(limit, windowMs) {
    this.limit = limit;
    this.windowMs = windowMs;
    this.requests = new Map(); // userId -> [timestamps]
  }
  
  isAllowed(userId) {
    const now = Date.now();
    const timestamps = this.requests.get(userId) || [];
    
    // Remove timestamps outside window
    const validTimestamps = timestamps.filter(
      time => now - time < this.windowMs
    );
    
    if (validTimestamps.length < this.limit) {
      validTimestamps.push(now);
      this.requests.set(userId, validTimestamps);
      return { 
        allowed: true, 
        remaining: this.limit - validTimestamps.length 
      };
    }
    
    // Rate limited
    const oldestTimestamp = validTimestamps[0];
    const resetTime = oldestTimestamp + this.windowMs;
    return { 
      allowed: false, 
      remaining: 0,
      resetAt: new Date(resetTime),
      retryAfter: Math.ceil((resetTime - now) / 1000)
    };
  }
}

// Usage
const limiter = new SlidingWindowLogRateLimiter(100, 60000);

const result = limiter.isAllowed('user123');
console.log(result);
```

**Pros:** Accurate, no burst issues
**Cons:** High memory usage (stores every timestamp)

### 3. Sliding Window Counter

Hybrid approach. Combines fixed windows with weighted counts.

```javascript
class SlidingWindowCounterRateLimiter {
  constructor(limit, windowMs) {
    this.limit = limit;
    this.windowMs = windowMs;
    this.windows = new Map(); // userId -> { current, previous, currentStart }
  }
  
  isAllowed(userId) {
    const now = Date.now();
    const userWindows = this.windows.get(userId) || {
      current: 0,
      previous: 0,
      currentStart: now
    };
    
    // Check if we need to slide the window
    const elapsed = now - userWindows.currentStart;
    
    if (elapsed >= this.windowMs) {
      // Slide to new window
      userWindows.previous = userWindows.current;
      userWindows.current = 0;
      userWindows.currentStart = now;
    }
    
    // Calculate weighted count
    const percentageInCurrentWindow = elapsed / this.windowMs;
    const percentageInPreviousWindow = 1 - percentageInCurrentWindow;
    
    const weightedCount = 
      userWindows.current + 
      (userWindows.previous * percentageInPreviousWindow);
    
    if (weightedCount < this.limit) {
      userWindows.current++;
      this.windows.set(userId, userWindows);
      return { 
        allowed: true, 
        remaining: Math.floor(this.limit - weightedCount - 1)
      };
    }
    
    // Rate limited
    const resetTime = userWindows.currentStart + this.windowMs;
    return { 
      allowed: false, 
      remaining: 0,
      resetAt: new Date(resetTime),
      retryAfter: Math.ceil((resetTime - now) / 1000)
    };
  }
}

// Usage
const limiter = new SlidingWindowCounterRateLimiter(100, 60000);
```

**Pros:** Smooth distribution, low memory
**Cons:** Slightly less accurate than log method

### 4. Token Bucket

Tokens are added at constant rate. Each request consumes a token.

```javascript
class TokenBucketRateLimiter {
  constructor(capacity, refillRate, refillIntervalMs) {
    this.capacity = capacity; // Max tokens
    this.refillRate = refillRate; // Tokens added per interval
    this.refillIntervalMs = refillIntervalMs;
    this.buckets = new Map(); // userId -> { tokens, lastRefill }
  }
  
  refillBucket(bucket) {
    const now = Date.now();
    const timePassed = now - bucket.lastRefill;
    const intervals = Math.floor(timePassed / this.refillIntervalMs);
    
    if (intervals > 0) {
      bucket.tokens = Math.min(
        this.capacity,
        bucket.tokens + (intervals * this.refillRate)
      );
      bucket.lastRefill = now;
    }
  }
  
  isAllowed(userId, cost = 1) {
    const now = Date.now();
    let bucket = this.buckets.get(userId);
    
    if (!bucket) {
      bucket = {
        tokens: this.capacity,
        lastRefill: now
      };
      this.buckets.set(userId, bucket);
    }
    
    // Refill bucket
    this.refillBucket(bucket);
    
    // Check if enough tokens
    if (bucket.tokens >= cost) {
      bucket.tokens -= cost;
      return { 
        allowed: true, 
        remaining: bucket.tokens 
      };
    }
    
    // Calculate when next token available
    const tokensNeeded = cost - bucket.tokens;
    const intervalsNeeded = Math.ceil(tokensNeeded / this.refillRate);
    const retryAfter = Math.ceil((intervalsNeeded * this.refillIntervalMs) / 1000);
    
    return { 
      allowed: false, 
      remaining: 0,
      retryAfter
    };
  }
}

// Usage: 10 tokens capacity, refill 1 token per second
const limiter = new TokenBucketRateLimiter(10, 1, 1000);

// Different costs for different operations
limiter.isAllowed('user123', 1); // Simple read: 1 token
limiter.isAllowed('user123', 3); // Complex query: 3 tokens
limiter.isAllowed('user123', 5); // Heavy operation: 5 tokens
```

**Pros:** 
- Allows bursts (up to capacity)
- Smooth refilling
- Different costs per operation

**Cons:** 
- More complex
- Harder to explain to users

### 5. Leaky Bucket

Requests enter a queue, processed at constant rate.

```javascript
class LeakyBucketRateLimiter {
  constructor(capacity, leakRate) {
    this.capacity = capacity; // Queue size
    this.leakRate = leakRate; // Requests per second
    this.queues = new Map(); // userId -> { queue, lastLeak }
  }
  
  leak(queue) {
    const now = Date.now();
    const timePassed = (now - queue.lastLeak) / 1000;
    const leaked = Math.floor(timePassed * this.leakRate);
    
    if (leaked > 0) {
      queue.size = Math.max(0, queue.size - leaked);
      queue.lastLeak = now;
    }
  }
  
  isAllowed(userId) {
    const now = Date.now();
    let queue = this.queues.get(userId);
    
    if (!queue) {
      queue = {
        size: 0,
        lastLeak: now
      };
      this.queues.set(userId, queue);
    }
    
    // Leak requests
    this.leak(queue);
    
    // Check capacity
    if (queue.size < this.capacity) {
      queue.size++;
      return { 
        allowed: true, 
        remaining: this.capacity - queue.size 
      };
    }
    
    // Queue full
    const retryAfter = Math.ceil((queue.size - this.capacity + 1) / this.leakRate);
    return { 
      allowed: false, 
      remaining: 0,
      retryAfter
    };
  }
}

// Usage: Capacity 100, process 10 requests/second
const limiter = new LeakyBucketRateLimiter(100, 10);
```

**Pros:** 
- Smooth traffic flow
- Predictable processing rate

**Cons:** 
- Doesn't allow bursts
- Requests can be delayed

---

## Implementation with Express.js

### Basic Middleware

```javascript
const rateLimit = require('express-rate-limit');

// Apply to all requests
const limiter = rateLimit({
  windowMs: 15 * 60 * 1000, // 15 minutes
  max: 100, // Limit each IP to 100 requests per windowMs
  message: {
    error: {
      code: 'RATE_LIMIT_EXCEEDED',
      message: 'Too many requests, please try again later.'
    }
  },
  standardHeaders: true, // Return rate limit info in headers
  legacyHeaders: false, // Disable X-RateLimit-* headers
  handler: (req, res) => {
    res.status(429).json({
      error: {
        code: 'RATE_LIMIT_EXCEEDED',
        message: 'Too many requests, please try again later.',
        retryAfter: req.rateLimit.resetTime
      }
    });
  }
});

app.use(limiter);
```

### Per-Route Limits

```javascript
// Strict limit for authentication
const authLimiter = rateLimit({
  windowMs: 15 * 60 * 1000, // 15 minutes
  max: 5, // 5 attempts
  skipSuccessfulRequests: true, // Don't count successful logins
  message: 'Too many login attempts, please try again later.'
});

app.post('/auth/login', authLimiter, async (req, res) => {
  // Login logic
});

// Generous limit for reads
const readLimiter = rateLimit({
  windowMs: 60 * 1000, // 1 minute
  max: 100
});

app.get('/api/users', readLimiter, async (req, res) => {
  // Get users
});

// Strict limit for writes
const writeLimiter = rateLimit({
  windowMs: 60 * 1000, // 1 minute
  max: 20
});

app.post('/api/users', writeLimiter, async (req, res) => {
  // Create user
});
```

### Custom Key Generator

```javascript
// Rate limit by user ID instead of IP
const userLimiter = rateLimit({
  windowMs: 60 * 1000,
  max: 100,
  keyGenerator: (req) => {
    // Use authenticated user ID
    return req.user?.id || req.ip;
  }
});

// Rate limit by API key
const apiKeyLimiter = rateLimit({
  windowMs: 60 * 1000,
  max: async (req) => {
    // Different limits per tier
    const apiKey = req.headers['x-api-key'];
    const key = await db.apiKeys.findOne({ key: apiKey });
    
    if (!key) return 10; // No key = strict limit
    if (key.tier === 'free') return 100;
    if (key.tier === 'basic') return 1000;
    if (key.tier === 'premium') return 10000;
    return 10;
  },
  keyGenerator: (req) => {
    return req.headers['x-api-key'] || req.ip;
  }
});
```

### Custom Headers

```javascript
const limiter = rateLimit({
  windowMs: 60 * 1000,
  max: 100,
  handler: (req, res) => {
    const resetTime = new Date(req.rateLimit.resetTime);
    const retryAfter = Math.ceil((resetTime - Date.now()) / 1000);
    
    res.status(429)
      .header('X-RateLimit-Limit', req.rateLimit.limit)
      .header('X-RateLimit-Remaining', 0)
      .header('X-RateLimit-Reset', Math.ceil(resetTime.getTime() / 1000))
      .header('Retry-After', retryAfter)
      .json({
        error: {
          code: 'RATE_LIMIT_EXCEEDED',
          message: `Rate limit exceeded. Try again in ${retryAfter} seconds.`,
          limit: req.rateLimit.limit,
          resetAt: resetTime.toISOString(),
          retryAfter
        }
      });
  }
});
```

---

## Distributed Rate Limiting with Redis

For multiple servers, use shared storage.

### Redis Implementation

```javascript
const Redis = require('ioredis');
const redis = new Redis();

class RedisRateLimiter {
  constructor(redis, limit, windowMs) {
    this.redis = redis;
    this.limit = limit;
    this.windowMs = windowMs;
  }
  
  async isAllowed(key) {
    const now = Date.now();
    const windowStart = now - this.windowMs;
    
    // Redis key
    const redisKey = `rate_limit:${key}`;
    
    // Multi command for atomicity
    const pipeline = this.redis.pipeline();
    
    // Remove old entries
    pipeline.zremrangebyscore(redisKey, 0, windowStart);
    
    // Count entries in current window
    pipeline.zcard(redisKey);
    
    // Add current request
    pipeline.zadd(redisKey, now, `${now}-${Math.random()}`);
    
    // Set expiry
    pipeline.expire(redisKey, Math.ceil(this.windowMs / 1000));
    
    const results = await pipeline.exec();
    const count = results[1][1]; // Count result
    
    if (count < this.limit) {
      return {
        allowed: true,
        remaining: this.limit - count - 1
      };
    }
    
    // Get oldest entry for reset time
    const oldest = await this.redis.zrange(redisKey, 0, 0, 'WITHSCORES');
    const resetTime = parseInt(oldest[1]) + this.windowMs;
    const retryAfter = Math.ceil((resetTime - now) / 1000);
    
    // Remove the request we just added (not allowed)
    await this.redis.zrem(redisKey, `${now}-${Math.random()}`);
    
    return {
      allowed: false,
      remaining: 0,
      resetAt: new Date(resetTime),
      retryAfter
    };
  }
}

// Middleware
const rateLimiter = new RedisRateLimiter(redis, 100, 60000);

app.use(async (req, res, next) => {
  const key = req.user?.id || req.ip;
  const result = await rateLimiter.isAllowed(key);
  
  // Set headers
  res.header('X-RateLimit-Limit', 100);
  res.header('X-RateLimit-Remaining', result.remaining);
  
  if (result.allowed) {
    next();
  } else {
    res.header('X-RateLimit-Reset', Math.ceil(result.resetAt.getTime() / 1000));
    res.header('Retry-After', result.retryAfter);
    
    res.status(429).json({
      error: {
        code: 'RATE_LIMIT_EXCEEDED',
        message: `Rate limit exceeded. Try again in ${result.retryAfter} seconds.`,
        retryAfter: result.retryAfter
      }
    });
  }
});
```

### Redis Token Bucket

```javascript
class RedisTokenBucketRateLimiter {
  constructor(redis, capacity, refillRate, refillIntervalMs) {
    this.redis = redis;
    this.capacity = capacity;
    this.refillRate = refillRate;
    this.refillIntervalMs = refillIntervalMs;
  }
  
  async isAllowed(key, cost = 1) {
    const now = Date.now();
    const bucketKey = `token_bucket:${key}`;
    
    // Lua script for atomic operations
    const script = `
      local capacity = tonumber(ARGV[1])
      local refill_rate = tonumber(ARGV[2])
      local refill_interval = tonumber(ARGV[3])
      local cost = tonumber(ARGV[4])
      local now = tonumber(ARGV[5])
      
      local bucket = redis.call('HMGET', KEYS[1], 'tokens', 'last_refill')
      local tokens = tonumber(bucket[1]) or capacity
      local last_refill = tonumber(bucket[2]) or now
      
      -- Refill tokens
      local time_passed = now - last_refill
      local intervals = math.floor(time_passed / refill_interval)
      
      if intervals > 0 then
        tokens = math.min(capacity, tokens + (intervals * refill_rate))
        last_refill = now
      end
      
      -- Check if enough tokens
      if tokens >= cost then
        tokens = tokens - cost
        redis.call('HMSET', KEYS[1], 'tokens', tokens, 'last_refill', last_refill)
        redis.call('EXPIRE', KEYS[1], 3600)
        return {1, tokens}
      else
        return {0, tokens}
      end
    `;
    
    const result = await this.redis.eval(
      script,
      1,
      bucketKey,
      this.capacity,
      this.refillRate,
      this.refillIntervalMs,
      cost,
      now
    );
    
    const [allowed, remaining] = result;
    
    if (allowed === 1) {
      return { allowed: true, remaining };
    }
    
    // Calculate retry time
    const tokensNeeded = cost - remaining;
    const intervalsNeeded = Math.ceil(tokensNeeded / this.refillRate);
    const retryAfter = Math.ceil((intervalsNeeded * this.refillIntervalMs) / 1000);
    
    return { allowed: false, remaining: 0, retryAfter };
  }
}

// Usage
const limiter = new RedisTokenBucketRateLimiter(redis, 100, 10, 1000);

app.use(async (req, res, next) => {
  const key = req.user?.id || req.ip;
  const result = await limiter.isAllowed(key);
  
  if (result.allowed) {
    next();
  } else {
    res.status(429).json({
      error: {
        code: 'RATE_LIMIT_EXCEEDED',
        message: `Rate limit exceeded. Try again in ${result.retryAfter} seconds.`,
        retryAfter: result.retryAfter
      }
    });
  }
});
```

---

## Rate Limiting Strategies

### 1. By IP Address

```javascript
app.use(rateLimit({
  windowMs: 60 * 1000,
  max: 100,
  keyGenerator: (req) => req.ip
}));
```

**Pros:** Simple, no authentication needed
**Cons:** 
- Shared IPs (NAT, proxies) penalize multiple users
- VPNs can bypass

### 2. By User ID

```javascript
app.use(rateLimit({
  windowMs: 60 * 1000,
  max: 100,
  keyGenerator: (req) => req.user?.id || req.ip
}));
```

**Pros:** Fair per user, works with authentication
**Cons:** Requires authentication

### 3. By API Key

```javascript
app.use(rateLimit({
  windowMs: 60 * 1000,
  max: 100,
  keyGenerator: (req) => req.headers['x-api-key'] || req.ip
}));
```

**Pros:** Easy to track, revocable
**Cons:** Keys can be stolen

### 4. Tiered Limits

```javascript
const getTierLimit = (tier) => {
  switch (tier) {
    case 'free': return 100;
    case 'basic': return 1000;
    case 'premium': return 10000;
    case 'enterprise': return 100000;
    default: return 10;
  }
};

app.use(rateLimit({
  windowMs: 60 * 1000,
  max: async (req) => {
    const apiKey = req.headers['x-api-key'];
    if (!apiKey) return 10;
    
    const key = await db.apiKeys.findOne({ key: apiKey });
    return getTierLimit(key?.tier);
  },
  keyGenerator: (req) => req.headers['x-api-key'] || req.ip
}));
```

### 5. Cost-Based Limits

Different operations have different costs.

```javascript
const getOperationCost = (req) => {
  // Read operations: 1 token
  if (req.method === 'GET') return 1;
  
  // Create operations: 2 tokens
  if (req.method === 'POST') return 2;
  
  // Update operations: 2 tokens
  if (req.method === 'PUT' || req.method === 'PATCH') return 2;
  
  // Delete operations: 3 tokens
  if (req.method === 'DELETE') return 3;
  
  // Heavy operations: 5 tokens
  if (req.path.includes('/export') || req.path.includes('/report')) return 5;
  
  return 1;
};

app.use(async (req, res, next) => {
  const key = req.user?.id || req.ip;
  const cost = getOperationCost(req);
  
  const result = await tokenBucketLimiter.isAllowed(key, cost);
  
  if (result.allowed) {
    next();
  } else {
    res.status(429).json({
      error: {
        code: 'RATE_LIMIT_EXCEEDED',
        message: `Insufficient tokens. Operation costs ${cost} tokens.`,
        cost,
        retryAfter: result.retryAfter
      }
    });
  }
});
```

### 6. Concurrent Request Limiting

Limit simultaneous requests per user.

```javascript
class ConcurrentRequestLimiter {
  constructor(maxConcurrent) {
    this.maxConcurrent = maxConcurrent;
    this.active = new Map(); // userId -> count
  }
  
  acquire(userId) {
    const count = this.active.get(userId) || 0;
    
    if (count >= this.maxConcurrent) {
      return { allowed: false, active: count };
    }
    
    this.active.set(userId, count + 1);
    return { allowed: true, active: count + 1 };
  }
  
  release(userId) {
    const count = this.active.get(userId) || 0;
    if (count > 0) {
      this.active.set(userId, count - 1);
    }
  }
}

const concurrentLimiter = new ConcurrentRequestLimiter(5);

app.use((req, res, next) => {
  const userId = req.user?.id || req.ip;
  const result = concurrentLimiter.acquire(userId);
  
  if (!result.allowed) {
    return res.status(429).json({
      error: {
        code: 'TOO_MANY_CONCURRENT_REQUESTS',
        message: `Maximum ${concurrentLimiter.maxConcurrent} concurrent requests allowed.`,
        active: result.active
      }
    });
  }
  
  // Release on response finish
  res.on('finish', () => {
    concurrentLimiter.release(userId);
  });
  
  next();
});
```

---

## Client-Side Handling

### Respecting Rate Limits

```javascript
class RateLimitedClient {
  constructor(baseUrl) {
    this.baseUrl = baseUrl;
    this.rateLimitInfo = {
      limit: null,
      remaining: null,
      reset: null
    };
  }
  
  async request(url, options = {}) {
    // Check if rate limited
    if (this.rateLimitInfo.remaining === 0) {
      const now = Date.now();
      const resetTime = new Date(this.rateLimitInfo.reset * 1000).getTime();
      
      if (now < resetTime) {
        const waitMs = resetTime - now;
        console.log(`Rate limited. Waiting ${waitMs}ms...`);
        await this.sleep(waitMs);
      }
    }
    
    const response = await fetch(this.baseUrl + url, options);
    
    // Update rate limit info from headers
    this.rateLimitInfo = {
      limit: parseInt(response.headers.get('X-RateLimit-Limit')),
      remaining: parseInt(response.headers.get('X-RateLimit-Remaining')),
      reset: parseInt(response.headers.get('X-RateLimit-Reset'))
    };
    
    // Handle 429
    if (response.status === 429) {
      const retryAfter = parseInt(response.headers.get('Retry-After'));
      console.log(`Rate limited. Retrying after ${retryAfter}s...`);
      await this.sleep(retryAfter * 1000);
      return this.request(url, options); // Retry
    }
    
    return response.json();
  }
  
  sleep(ms) {
    return new Promise(resolve => setTimeout(resolve, ms));
  }
  
  getRemainingRequests() {
    return this.rateLimitInfo.remaining;
  }
  
  getResetTime() {
    return new Date(this.rateLimitInfo.reset * 1000);
  }
}

// Usage
const client = new RateLimitedClient('https://api.example.com');

const data = await client.request('/users');
console.log(`Remaining requests: ${client.getRemainingRequests()}`);
console.log(`Resets at: ${client.getResetTime()}`);
```

### Exponential Backoff

```javascript
class RateLimitedClientWithBackoff {
  async requestWithBackoff(url, options = {}, maxRetries = 5) {
    let retries = 0;
    
    while (retries < maxRetries) {
      try {
        const response = await fetch(url, options);
        
        if (response.status === 429) {
          const retryAfter = parseInt(response.headers.get('Retry-After')) || 1;
          
          // Exponential backoff: 1s, 2s, 4s, 8s, 16s
          const backoffSeconds = Math.min(retryAfter * Math.pow(2, retries), 60);
          
          console.log(`Rate limited. Retry ${retries + 1}/${maxRetries} in ${backoffSeconds}s...`);
          
          await this.sleep(backoffSeconds * 1000);
          retries++;
          continue;
        }
        
        return response.json();
      } catch (error) {
        if (retries === maxRetries - 1) throw error;
        
        const backoffSeconds = Math.pow(2, retries);
        console.log(`Error. Retrying in ${backoffSeconds}s...`);
        await this.sleep(backoffSeconds * 1000);
        retries++;
      }
    }
    
    throw new Error('Max retries exceeded');
  }
  
  sleep(ms) {
    return new Promise(resolve => setTimeout(resolve, ms));
  }
}

// Usage
const client = new RateLimitedClientWithBackoff();
const data = await client.requestWithBackoff('https://api.example.com/users');
```

### Request Queue

```javascript
class RequestQueue {
  constructor(requestsPerSecond) {
    this.requestsPerSecond = requestsPerSecond;
    this.queue = [];
    this.processing = false;
  }
  
  async add(url, options = {}) {
    return new Promise((resolve, reject) => {
      this.queue.push({ url, options, resolve, reject });
      this.process();
    });
  }
  
  async process() {
    if (this.processing || this.queue.length === 0) return;
    
    this.processing = true;
    
    while (this.queue.length > 0) {
      const { url, options, resolve, reject } = this.queue.shift();
      
      try {
        const response = await fetch(url, options);
        const data = await response.json();
        resolve(data);
      } catch (error) {
        reject(error);
      }
      
      // Wait before next request
      const delayMs = 1000 / this.requestsPerSecond;
      await this.sleep(delayMs);
    }
    
    this.processing = false;
  }
  
  sleep(ms) {
    return new Promise(resolve => setTimeout(resolve, ms));
  }
}

// Usage: Max 10 requests per second
const queue = new RequestQueue(10);

// Add requests to queue
const promises = [];
for (let i = 0; i < 100; i++) {
  promises.push(queue.add(`https://api.example.com/users/${i}`));
}

// All requests will be processed at 10 req/s
const results = await Promise.all(promises);
```

---

## Testing Rate Limits

```javascript
describe('Rate Limiting', () => {
  it('should allow requests within limit', async () => {
    // Make 100 requests (within limit)
    for (let i = 0; i < 100; i++) {
      const response = await request(app)
        .get('/api/users')
        .set('X-API-Key', 'test-key');
      
      expect(response.status).toBe(200);
    }
  });
  
  it('should return 429 when limit exceeded', async () => {
    // Make 100 requests (at limit)
    for (let i = 0; i < 100; i++) {
      await request(app)
        .get('/api/users')
        .set('X-API-Key', 'test-key');
    }
    
    // 101st request should be rate limited
    const response = await request(app)
      .get('/api/users')
      .set('X-API-Key', 'test-key');
    
    expect(response.status).toBe(429);
    expect(response.body.error.code).toBe('RATE_LIMIT_EXCEEDED');
  });
  
  it('should include rate limit headers', async () => {
    const response = await request(app)
      .get('/api/users')
      .set('X-API-Key', 'test-key');
    
    expect(response.headers).toHaveProperty('x-ratelimit-limit');
    expect(response.headers).toHaveProperty('x-ratelimit-remaining');
    expect(response.headers).toHaveProperty('x-ratelimit-reset');
  });
  
  it('should reset after time window', async () => {
    // Make 100 requests (at limit)
    for (let i = 0; i < 100; i++) {
      await request(app)
        .get('/api/users')
        .set('X-API-Key', 'test-key');
    }
    
    // Wait for window to expire
    await new Promise(resolve => setTimeout(resolve, 60000)); // 1 minute
    
    // Should allow requests again
    const response = await request(app)
      .get('/api/users')
      .set('X-API-Key', 'test-key');
    
    expect(response.status).toBe(200);
  });
  
  it('should have different limits per tier', async () => {
    // Free tier: 100 requests
    for (let i = 0; i < 100; i++) {
      const response = await request(app)
        .get('/api/users')
        .set('X-API-Key', 'free-tier-key');
      expect(response.status).toBe(200);
    }
    
    // 101st should fail
    const freeResponse = await request(app)
      .get('/api/users')
      .set('X-API-Key', 'free-tier-key');
    expect(freeResponse.status).toBe(429);
    
    // Premium tier: 10000 requests
    for (let i = 0; i < 1000; i++) {
      const response = await request(app)
        .get('/api/users')
        .set('X-API-Key', 'premium-tier-key');
      expect(response.status).toBe(200);
    }
  });
});
```

---

## Real-World Examples

### GitHub API

```http
GET https://api.github.com/users/octocat

HTTP/1.1 200 OK
X-RateLimit-Limit: 60
X-RateLimit-Remaining: 59
X-RateLimit-Reset: 1642684800
X-RateLimit-Used: 1
X-RateLimit-Resource: core

// Authenticated: 5,000 requests/hour
// Unauthenticated: 60 requests/hour
// Search: 30 requests/minute
```

### Twitter API

```http
GET https://api.twitter.com/2/tweets/search/recent

HTTP/1.1 200 OK
x-rate-limit-limit: 450
x-rate-limit-remaining: 449
x-rate-limit-reset: 1642684800

// Free tier: 500,000 tweets/month
// Basic tier: 2,000,000 tweets/month
// Pro tier: Unlimited
```

### Stripe API

```http
POST https://api.stripe.com/v1/charges

HTTP/1.1 200 OK
RateLimit-Limit: 100
RateLimit-Remaining: 99
RateLimit-Reset: 1642684800

// 100 requests per second in test mode
// 100 requests per second in live mode
// Higher limits for verified businesses
```

---

## Best Practices

### 1. Always Include Headers

```javascript
// ✅ Good: Always set rate limit headers
res.header('X-RateLimit-Limit', 100);
res.header('X-RateLimit-Remaining', 95);
res.header('X-RateLimit-Reset', resetTimestamp);

// ❌ Bad: No headers
res.json({ data });
```

### 2. Use Appropriate Limits

```javascript
// ✅ Good: Different limits for different operations
GET /api/users        → 100 requests/minute (reads are cheap)
POST /api/users       → 20 requests/minute (writes are expensive)
POST /auth/login      → 5 requests/15 minutes (prevent brute force)
POST /api/export      → 5 requests/hour (very expensive)

// ❌ Bad: Same limit for everything
All endpoints → 100 requests/minute
```

### 3. Provide Clear Error Messages

```javascript
// ✅ Good: Detailed error
{
  "error": {
    "code": "RATE_LIMIT_EXCEEDED",
    "message": "Rate limit exceeded. Try again in 45 seconds.",
    "limit": 100,
    "remaining": 0,
    "resetAt": "2022-01-20T12:00:00Z",
    "retryAfter": 45,
    "documentation": "https://api.example.com/docs/rate-limiting"
  }
}

// ❌ Bad: Vague error
{
  "error": "Too many requests"
}
```

### 4. Implement Retry-After

```javascript
// ✅ Good: Include Retry-After header
HTTP/1.1 429 Too Many Requests
Retry-After: 45

// ❌ Bad: No retry guidance
HTTP/1.1 429 Too Many Requests
```

### 5. Skip Internal Requests

```javascript
// ✅ Good: Skip rate limiting for internal services
app.use((req, res, next) => {
  if (req.headers['x-internal-service'] === process.env.INTERNAL_SECRET) {
    return next(); // Skip rate limiting
  }
  
  rateLimiter(req, res, next);
});

// ❌ Bad: Rate limit internal services
```

### 6. Use Distributed Storage

```javascript
// ✅ Good: Redis for multiple servers
const limiter = new RedisRateLimiter(redis, 100, 60000);

// ❌ Bad: In-memory for multiple servers
const limiter = new Map(); // Each server has own count!
```

### 7. Log Rate Limit Events

```javascript
app.use(rateLimit({
  windowMs: 60 * 1000,
  max: 100,
  handler: (req, res) => {
    // Log rate limit event
    logger.warn('Rate limit exceeded', {
      ip: req.ip,
      userId: req.user?.id,
      path: req.path,
      headers: req.headers
    });
    
    res.status(429).json({ error: 'Rate limit exceeded' });
  }
}));
```

### 8. Allow Bursts

```javascript
// ✅ Good: Token bucket allows bursts
const limiter = new TokenBucketRateLimiter(100, 10, 1000);
// Can burst up to 100 requests, then 10 per second

// ❌ Bad: Strict fixed window
const limiter = new FixedWindowRateLimiter(60, 60000);
// Exactly 60 per minute, no flexibility
```

---

## Common Mistakes

### Mistake 1: No Rate Limit Headers

```javascript
// ❌ Bad
if (rateLimited) {
  return res.status(429).json({ error: 'Rate limited' });
}

// ✅ Good
if (rateLimited) {
  return res
    .status(429)
    .header('X-RateLimit-Limit', limit)
    .header('X-RateLimit-Remaining', 0)
    .header('X-RateLimit-Reset', resetTime)
    .header('Retry-After', retryAfter)
    .json({ error: 'Rate limited' });
}
```

### Mistake 2: Rate Limiting Before Authentication

```javascript
// ❌ Bad: Can't identify user
app.use(rateLimiter); // Uses IP only
app.use(authenticate);

// ✅ Good: Rate limit by user ID
app.use(authenticate);
app.use(rateLimiter); // Can use req.user.id
```

### Mistake 3: Not Handling Distributed Systems

```javascript
// ❌ Bad: In-memory storage with multiple servers
const counts = new Map(); // Each server has different count!

// ✅ Good: Shared Redis storage
const redis = new Redis();
const limiter = new RedisRateLimiter(redis, 100, 60000);
```

### Mistake 4: Same Limit for All Operations

```javascript
// ❌ Bad: Expensive operations same as cheap ones
GET /api/users        → 100/min
POST /api/export-all  → 100/min (this will kill your server!)

// ✅ Good: Different limits
GET /api/users        → 100/min
POST /api/export-all  → 1/hour
```

---

## Summary

### Key Concepts

- **Rate Limiting** = Control requests per time window
- **Purpose** = Prevent abuse, ensure fair usage, control costs
- **Headers** = X-RateLimit-Limit, X-RateLimit-Remaining, X-RateLimit-Reset, Retry-After
- **429 Status** = Too Many Requests

### Algorithms

1. **Fixed Window** = Simple, but allows bursts
2. **Sliding Window Log** = Accurate, high memory
3. **Sliding Window Counter** = Balanced approach
4. **Token Bucket** = Allows bursts, flexible costs
5. **Leaky Bucket** = Smooth flow, no bursts

### Implementation Strategies

- **By IP** = Simple, prone to issues with shared IPs
- **By User** = Fair, requires authentication
- **By API Key** = Trackable, revocable
- **Tiered** = Different limits per subscription tier
- **Cost-Based** = Different costs per operation

### Best Practices

✅ Always include rate limit headers
✅ Use appropriate limits per endpoint
✅ Provide clear error messages with retry guidance
✅ Use distributed storage (Redis) for multiple servers
✅ Different limits for read vs write operations
✅ Log rate limit events for monitoring
✅ Allow bursts for better UX
✅ Skip rate limiting for internal services

### Client Handling

- Respect Retry-After header
- Implement exponential backoff
- Queue requests to stay under limits
- Monitor remaining quota

---

## Next Steps

Explore related topics:
- Pagination strategies for large datasets
- Caching to reduce API calls
- API authentication and authorization
- Monitoring and alerting for rate limit events
- DDoS protection and WAF configuration
